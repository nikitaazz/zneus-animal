{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d61fa-0740-46bf-8388-9b9a415be1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import kagglehub\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3a5e4-2907-4495-8c1b-cd96400b831d",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52b584-87a6-4a11-a533-078c981e3a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d94b4-8059-45d1-a940-4b0cbf6b79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"alessiocorrado99/animals10\")+\"\\\\raw-img\"\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb542a2-4220-4eb6-badc-94c4a233b96d",
   "metadata": {},
   "source": [
    "Animals type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea00acc-39df-4892-9cc5-e618eba5cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = os.listdir(path)\n",
    "print(clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd4985-b9f0-4984-9794-e5e8f6a03a4c",
   "metadata": {},
   "source": [
    "Num of photos in each folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d48dc3-8bb4-4a45-a848-e7ac6fa632a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Class Name':<20} | {'Count'}\")\n",
    "print(\"-\" * 30)\n",
    "for cl in clases:\n",
    "    folder_path = os.path.join(path, cl)\n",
    "    count = len(os.listdir(folder_path))\n",
    "    print(f\"{cl:<20} | {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c42f7-e9cd-4ffd-b4bc-7249dca7bae5",
   "metadata": {},
   "source": [
    "See what we have in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b69d8c7-9896-4303-98fa-ed4d16c5f3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cl in clases:\n",
    "    n=3\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    a = path+\"\\\\\"+cl\n",
    "    imgs = os.listdir(a)\n",
    "    i=1\n",
    "    for _ in range(n):\n",
    "        img_path = os.path.join(a, imgs[_])\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        plt.subplot(4, n, i)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca15a1e-1f08-452b-87d1-b00aae80a184",
   "metadata": {},
   "source": [
    "Analyze avg size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a16b73d-5f28-4b52-8e45-d7e24281b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Class':<20} | {'Min W':<6} | {'Max W':<6} | {'Avg W':<8} | {'Min H':<6} | {'Max H':<6} | {'Avg H':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for cl in clases:\n",
    "    folder_path = os.path.join(path, cl)\n",
    "    widths = []\n",
    "    heights = []\n",
    "    \n",
    "    # Get all images in the class folder\n",
    "    imgs = os.listdir(folder_path)\n",
    "    \n",
    "    for im_name in imgs:\n",
    "        img_path = os.path.join(folder_path, im_name)\n",
    "        try:\n",
    "            with Image.open(img_path) as im:\n",
    "                w, h = im.size\n",
    "                widths.append(w)\n",
    "                heights.append(h)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {img_path}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    if widths and heights:\n",
    "        min_w = min(widths)\n",
    "        max_w = max(widths)\n",
    "        avg_w = sum(widths) / len(widths)\n",
    "        \n",
    "        min_h = min(heights)\n",
    "        max_h = max(heights)\n",
    "        avg_h = sum(heights) / len(heights)\n",
    "        \n",
    "        print(f\"{cl:<20} | {min_w:<6} | {max_w:<6} | {avg_w:<8.1f} | {min_h:<6} | {max_h:<6} | {avg_h:<8.1f}\")\n",
    "    else:\n",
    "        print(f\"{cl:<20} | No images found or error reading images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90effb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Image Channels\n",
    "modes = {}\n",
    "channels_count = {}\n",
    "\n",
    "print(\"Analyzing image modes and channels\")\n",
    "for cl in clases:\n",
    "    folder = os.path.join(path, cl)\n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                # Count modes (RGB, L, CMYK, etc.)\n",
    "                modes[img.mode] = modes.get(img.mode, 0) + 1\n",
    "                # Count channels\n",
    "                c = len(img.getbands())\n",
    "                channels_count[c] = channels_count.get(c, 0) + 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(\"Image Modes:\", modes)\n",
    "print(\"Channel Counts:\", channels_count)\n",
    "\n",
    "if 1 in channels_count or 4 in channels_count:\n",
    "    print(\"\\nNote: Dataset contains images with different channel counts.\")\n",
    "    print(\"We will convert all images to RGB (3 channels/parameters per pixel) during preprocessing.\")\n",
    "else:\n",
    "    print(\"\\nAll images are already 3 channels (RGB).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292f99f-84ba-4759-835e-0635b04558cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "labels = []\n",
    "class_names = sorted(os.listdir(path))\n",
    "\n",
    "class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "for cl in clases:\n",
    "    a = path+\"\\\\\"+cl\n",
    "    # Verify folder exists\n",
    "    if not os.path.isdir(a):\n",
    "        continue\n",
    "        \n",
    "    for img in os.listdir(a):\n",
    "        files.append(os.path.join(a, img))\n",
    "        labels.append(class_to_idx[cl])\n",
    "\n",
    "print(f\"Total images loaded: {len(files)}\")\n",
    "print(f\"Total classes: {len(class_names)}\")\n",
    "print(f\"Class mapping: {class_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe7b4a1-ed23-415b-b44e-c0113665fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting dataset into Train and Test sets...\")\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "    files, labels,\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_files)}\")\n",
    "print(f\"Testing samples: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b502c5-c55c-4853-810a-a1c700d74236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Budeme vyuzivat accuracy a f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe98d9-9386-444c-a044-d0ee77761591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training transformations with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")), # Ensure 3 channels (R, G, B)\n",
    "    transforms.Resize((170, 170)),                 # Resize to consistent size\n",
    "    transforms.RandomHorizontalFlip(p=0.5),        # Data Augmentation: Flip\n",
    "    transforms.RandomRotation(5),                  # Data Augmentation: Rotate\n",
    "    transforms.ColorJitter(                        # Data Augmentation: Color\n",
    "        brightness=0.15,\n",
    "        contrast=0.15\n",
    "    ),\n",
    "    transforms.ToTensor(),                         # Convert to Tensor (0-1 range)\n",
    "    transforms.Normalize(                          # Normalize to range [-1, 1]\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "print(\"Training transforms defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ee99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Augmentations\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def visualize_augmentations(files, transform, n_samples=3):\n",
    "    \"\"\"\n",
    "    Visualizes original images and their augmented versions.\n",
    "    \"\"\"\n",
    "    # Select random files\n",
    "    sample_files = random.sample(files, n_samples)\n",
    "    \n",
    "    for img_path in sample_files:\n",
    "        # Load original\n",
    "        original_img = Image.open(img_path)\n",
    "        \n",
    "        # Apply transform multiple times to see variations\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "        \n",
    "        # Show original\n",
    "        axes[0].imshow(original_img)\n",
    "        axes[0].set_title(\"Original\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        for i in range(1, 5):\n",
    "            # Apply transform\n",
    "            aug_tensor = transform(original_img)\n",
    "            \n",
    "            # Un-normalize and convert to numpy for display\n",
    "            # Using simple 0.5 mean/std\n",
    "            mean = np.array([0.5, 0.5, 0.5])\n",
    "            std = np.array([0.5, 0.5, 0.5])\n",
    "            \n",
    "            aug_img = aug_tensor.permute(1, 2, 0).numpy()\n",
    "            aug_img = std * aug_img + mean\n",
    "            aug_img = np.clip(aug_img, 0, 1)\n",
    "            \n",
    "            axes[i].imshow(aug_img)\n",
    "            axes[i].set_title(f\"Aug {i}\")\n",
    "            axes[i].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "print(\"Visualizing Training Augmentations:\")\n",
    "visualize_augmentations(train_files, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e2e6c-6b28-44f8-b219-292a0727c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test transformations (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.convert(\"RGB\")), # Ensure 3 channels\n",
    "    transforms.Resize((170, 170)),                 # Resize to consistent size\n",
    "    transforms.ToTensor(),                         # Convert to Tensor\n",
    "    transforms.Normalize(                          # Normalize to range [-1, 1]\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "])\n",
    "print(\"Test transforms defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_paths[idx]\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, self.labels[idx]\n",
    "\n",
    "# Initialize Datasets\n",
    "print(\"Initializing Datasets...\")\n",
    "train_dataset = AnimalDataset(train_files, train_labels, transform=train_transform)\n",
    "test_dataset = AnimalDataset(test_files, test_labels, transform=test_transform)\n",
    "\n",
    "# Initialize DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "print(f\"Initializing DataLoaders with batch size {BATCH_SIZE}...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Data preparation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Test Data\n",
    "print(\"Visualizing samples from Test Dataset (Preprocessed)...\")\n",
    "\n",
    "def visualize_dataset_samples(dataset, class_names, n_samples=5):\n",
    "    indices = random.sample(range(len(dataset)), n_samples)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_samples, figsize=(15, 3))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, label = dataset[idx]\n",
    "        \n",
    "        # Denormalize for visualization\n",
    "        mean = np.array([0.5, 0.5, 0.5])\n",
    "        std = np.array([0.5, 0.5, 0.5])\n",
    "        \n",
    "        img_display = image.permute(1, 2, 0).numpy()\n",
    "        img_display = std * img_display + mean\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img_display)\n",
    "        axes[i].set_title(class_names[label])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "visualize_dataset_samples(test_dataset, class_names, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
